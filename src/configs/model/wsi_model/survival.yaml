attention_probs_dropout_prob: 0.0
decoder_hidden_size: 256
decoder_intermediate_size: 512
decoder_num_attention_heads: 4
decoder_num_hidden_layers: 2
hidden_act: "gelu"
hidden_dropout_prob: 0.0
hidden_size: 256 # размерность скрытого слоя
# input_embedding_dim: 512
# size: 512
initializer_range: 0.02
intermediate_size: 1024
layer_norm_eps: 1e-12
mask_ratio: 0.0
model_type: "vit_mae"
norm_pix_loss: false
num_attention_heads: 4
num_channels: 3
num_hidden_layers: 4 
image_size: 256
patch_size: 16
qkv_bias: true
is_load_pretrained: false
pretrained_model_name: "mae 2 conv2d/wsi mae_split"
# pretrained_model_path: ""
output_dim: 20
max_patches_per_sample: 10
num_patches: 10
random_patch_selection: True
#pretrained_model_path: "facebook/vit-mae-base"
embeddings_layers:
  - name: "Conv2d"
    args: [3, 64, 4]
    kwargs: {stride: 4}
  - name: "ReLU"
  - name: "Conv2d"
    args: [64, 256, 4]
    kwargs: {stride: 4}
decoder_pred_layers:
  - name: "ConvTranspose2d"
    args:
      - 256    # input channels
      - 64     # intermediate channels
      - 4      # kernel_size
    kwargs:
      stride: 2
  - name: "GELU"
  - name: "ConvTranspose2d"
    args:
      - 64
      - 3      # RGB output
      - 4
    kwargs:
      stride: 2